{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3369,"status":"ok","timestamp":1734523780021,"user":{"displayName":"Žiga Emeršič","userId":"12587844837117157742"},"user_tz":-60},"id":"LR9wM8EHEKcv","outputId":"281e2757-82b0-47f6-be99-6835649dc605"},"outputs":[],"source":["!pip install insightface opencv-python-headless onnxruntime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18671,"status":"ok","timestamp":1734523802630,"user":{"displayName":"Žiga Emeršič","userId":"12587844837117157742"},"user_tz":-60},"id":"XC77-AATDP0I","outputId":"5b92789d-4bb3-4923-902f-fd267c57a8b7"},"outputs":[],"source":["import insightface\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import cv2\n","import os\n","import glob\n","import torch\n","\n","# Load the InsightFace model\n","model = insightface.app.FaceAnalysis(name='buffalo_l')  # Pretrained model\n","model.prepare(ctx_id=0, det_size=(112, 112))\n","\n","def get_embedding(image_path):\n","    if not os.path.exists(image_path):\n","        print(f\"File not found: {image_path}\")\n","        return None\n","\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        print(f\"Error: Could not load image {image_path}\")\n","        return None\n","\n","    # Preprocess image: resize, normalize, transpose\n","    img = cv2.resize(img, (112, 112))  # Resize to model input size\n","    img = img[..., ::-1]  # Convert BGR to RGB\n","    img = np.transpose(img, (2, 0, 1))  # HWC -> CHW\n","    img = (img - 127.5) / 127.5  # Normalize to [-1, 1]\n","    img = np.expand_dims(img, axis=0).astype(np.float32)  # Add batch dimension\n","\n","    # Compute embedding using ONNX model\n","    with torch.no_grad():\n","        embedding = model.models['recognition'].forward(img)[0]\n","\n","    # We are returning feature vector for the whole image, because we already have a cropped face. However, you could use FaceAnalysis' face detection too.\n","    return embedding\n","\n","\n","\n","# Build known_faces gallery\n","faces_dir = \"faces\"\n","known_faces = {}\n","for label in ['a', 'b', 'c']:\n","    files = glob.glob(os.path.join(faces_dir, f\"{label}*.jpg\"))\n","    embeddings = [get_embedding(f) for f in files if get_embedding(f) is not None]\n","    known_faces[label] = np.mean(embeddings, axis=0) if embeddings else None\n","\n","# Recognition function\n","def recognize_face(test_image_path):\n","    test_emb = get_embedding(test_image_path)\n","    if test_emb is None: return \"Err\"\n","    scores = {name: cosine_similarity([test_emb], [ref_emb])[0][0] for name, ref_emb in known_faces.items() if ref_emb is not None}\n","    best_match = max(scores, key=scores.get)\n","    best_score = scores[best_match]\n","    return best_match, best_score\n","\n","\n","# Make predictions\n","test_images = [\"test-face-a.jpg\", \"test-face-b.jpg\"]\n","for img in test_images:\n","    identity, score = recognize_face(img)\n","    print(f\"Predicted identity for {img}: {identity} (Score: {score:.4f})\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPk0VzpoEOQzjk+NhSnJdcX","mount_file_id":"1LfTqS9HdhAELluU-Y_Hwisi2AWJRlDq2","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
